---
title: "Práctica 7. Regresión lineal - introducción"
author: "AE"
date: "03/11/2020"
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Previo

## Paquetería

```{r}

#install.packages("sjPlot", dependencies=T) # solito porque da problmas

library(sjPlot)

if (!require("pacman")) install.packages("pacman") # instala pacman si se requiere
pacman::p_load(tidyverse, 
               readxl,writexl,googlesheets4, # importar hojas de cálculo
               haven, foreign, # importación de dta y sav
               sjlabelled, # etiquetas
               janitor, skimr, #limpieza y verificación
               imputeTS, # para imputar valores
               srvyr, # Para el diseño muestral
               esquisse, # para usar ggplot de manera más amigable
               DescTools, # Paquete para estimaciones y pruebas
               infer, # tidy way 
               broom,  # Una escobita para limpiar (pero es para arreglar)
               estimatr, car, stargazer, ggpubr) # Para la regresión

```

## Directorio
En caso que no tengas un proyecto,establecer el directorio puede ayudar

```{r 1}
setwd("/Users/anaescoto/Dropbox/2020/2021-1 R para Demográfos/repo/R_Demo")
```

## Bases
Base de ECOVID - ML
```{r}
ecovid0420 <- read_dta("https://github.com/aniuxa/R_Demo/raw/master/datos/ecovid0420.dta")
```

# Análisis de varianza - Continuación
Análisis de varianza. Haremos la versión  más simple. Para ver el efecto de un factor sobre una variable cualitativa (oneway).
Revisaremos si la región de residencia de los trabajadores tiene un efecto en la distribución de los ingresos por trabajo. 

## Primero un gráfico
la ANOVA se basa en que nuestra variable es normal. Quitaremos los outliers

```{r}
lienzo_bi <-ecovid0420 %>% 
           filter(clase2==1  & !pe10_1==0) %>% 
           ggplot(aes(x=log(pe10_1), fill=as_factor(pos_ocu), 
           color=as_factor(pos_ocu),
           alpha=I(0.5)))

lienzo_bi + geom_density()
```

La prueba ANOVA o análisis de varianza, nos dice cuánto de nuestra variable se ve explicado por un factor.
En los modelos es mul útil guardar nuestros resultados como un objeto
```{r}
anova<-ecovid0420 %>% 
    filter(clase2==1) %>% 
      with(aov(pe10_1 ~ as_factor(pos_ocu)))

summary(anova)
```

Con tidy:

```{r}
tidy(anova)
```


### Comparación entre grupos
¿si es significativo cuáles diferencias entre los grupos lo son?
```{r}
TukeyHSD(anova)
```

## Supuestos de ANOVA

* Las observaciones se obtienen de forma independiente y aleatoria de la población definida por los niveles del factor
* Los datos de cada nivel de factor se distribuyen normalmente.
* Estas poblaciones normales tienen una varianza común. 

```{r}
#Prueba Bartlett para ver si las varianzas son iguales

ecovid0420 %>% 
    filter(clase2==1) %>% 
      with(bartlett.test(pe10_1 ~ as_factor(pos_ocu)))


```
La prueba tiene una Ho "Las varianzas son iguales"

```{r}
#Test Normalidad 
ecovid0420 %>% 
    filter(clase2==1) %>% 
      with(shapiro.test(pe10_1))

```
La prueba tiene una Ho "La variable es normal"


**¿Qué hacer?**

## Kruskal-Wallis test

Hay una prueba muy parecida que se basa en el orden de las observaciones, y se lee muy parecida a la ANOVA
```{r}
kruskal<-ecovid0420 %>% 
    filter(clase2==1) %>% 
      with(kruskal.test(pe10_1 ~ as_factor(pos_ocu)))

kruskal

tidy(kruskal)
```

Para ver las comparaciones tenemos que usar el dunn.test(), del paquet DescTools
```{r}

ecovid0420 %>% 
    filter(clase2==1) %>% 
      with(DunnTest(pe10_1 ~ as_factor(pos_ocu)))

```

Un gráfiquito accesorio:
```{r}

ecovid0420 %>% 
  filter(clase2==1) %>% 
ggpubr::ggviolin(x = "pos_ocu", y = "pe10_1", fill = "pos_ocu",
         add = "boxplot", add.params = list(fill = "white"))+
         stat_compare_means(label.y = 120)  # Add the p-value 
```

```{r}
comparaciones <- list( c("1", "2"), c("2", "3"), c("1", "3") )

```



Un gráfiquito accesorio 2:
```{r}

ecovid0420 %>% 
  filter(clase2==1) %>% 
ggpubr::ggviolin(x = "pos_ocu", y = "pe10_1", fill = "pos_ocu",
         palette = c("#00AFBB", "#E7B800", "#FC4E07"),
         add = "boxplot", add.params = list(fill = "white"))+
  stat_compare_means(comparisons = comparaciones, label = "p.signif")+ # Add significance levels
  stat_compare_means(label.y = 120)     # Add global the p-value 

```



# Previo a los modelos
Vamos a hacer una sub-base de nuestras posibles variables explicativas. Esto es importante porque sólo podemos comparar modelos con la misma cantidad de observaciones.


```{r}
mydata<- ecovid0420 %>% 
  filter(clase2==1) %>% # me quedo con los ocupados
  select(ent, pa1,starts_with("pb"), pos_ocu, pe10_1, fac_per, pa4_1)
tail(mydata)
```


```{r}
gg <- ggplot(mydata, aes(pb2, log(pe10_1)))
gg +  geom_jitter()

cor(mydata$pe10_1, mydata$pb2,  use = "pairwise")

```

## Prueba de hipótesis para la correlación

Una prueba de hipotésis sobe la correlación

```{r}
cor.test(mydata$pe10_1, mydata$pb2, use="pairwise.complete.obs")

```


```{r}
cor_test<-mydata %>% 
    with(cor.test(mydata$pe10_1, mydata$pb2, use = "pairwise")) # prueba de hipótesis.

#dos modos de visualizar el resultado
cor_test 
tidy(cor_test)
```

# Modelo simple

$$y=\beta_o+\beta_1x +\epsilon$$
Donde los parámetros $\beta_o$ y $\beta_1$ describen la pendiente y el intercepto de la población, respectivamente.


```{r}
hist(mydata$pe10_1)
hist(log(mydata$pe10_1))
```


No está muy bien comportada, pero ligeramente es mejor con logaritmo

```{r}
mydata$log_hrs<-log(mydata$pe10_1)
```


Una vez transformada nuestra variable, corremos el modelo

```{r}
modelo <-lm(log_hrs ~pb2, data=mydata)
summary(modelo) # resultado forma1
```

Con "tidy()"

```{r}
tidy(modelo) # Pruebas de hipótesis de los coeficientes
```

Para obtener los intervalos de confianza, podemos hacerlo a partir del siguiente comando:

```{r}
confint(modelo)
```


Para el ajuste global del modelo, podemos utilzar el comando "glance()" sobre el objeto de nuestro modelo, ello nos dará la información correspondiente:
```{r}
glance(modelo) # resultado ajuste global

```
Otra manera de ver este ajuste es con el comando "anova()":
```{r}
anova(modelo)
```

# Diagnósticos

```{r}
plot(modelo)

```




##1. Outliers y Normalidad
```{r}
# Assessing Outliers
outlierTest(modelo) # Bonferonni p-value for most extreme obs

out<-outlierTest(modelo) # guardamos en objeto
```


```{r}
ggpubr::ggqqplot(mydata$log_hrs)
```


```{r}
car::qqPlot(modelo, main="QQ Plot") #qq plot for studentized resid
```
##2. Homocedasticidad

```{r}
# non-constant error variance test
ncvTest(modelo)
# plot studentized residuals vs. fitted values 
spreadLevelPlot(modelo)
```



# Regresión Lineal múltiple

## Agregando una variable categórica

Cuando nosotros tenemos una variable categórica para la condición de sexo. [nota: seguimos haciendo el ejercicio, a pesar de que ya observamos en nuestro diagnóstico el modelo no cumple con los supuestos, pero lo haremos para fines ilustrativos]

```{r}
modelo1<-lm(log_hrs ~pb2 + as_label(pb1), data=mydata, na.action=na.exclude)
summary(modelo1)
```


Este modelo tiene coeficientes que deben leerse "condicionados". Es decir, en este caso tenemos que el coeficiente asociado a la edad, mantiene constante el valor de sexo y viceversa. 

¿Cómo saber is ha mejorado nuestro modelo? Podemos comparar el ajuste con la anova, es decir, una prueba F
```{r}
pruebaf0<-anova(modelo, modelo1)
pruebaf0
```



Como puedes ver, el resultado muestra un Df de 1 (lo que indica que el modelo más complejo tiene un parámetro adicional) y un valor p muy pequeño (<.001). Esto significa que agregar el sexo al modelo lleva a un ajuste significativamente mejor sobre el modelo original.

Podemos seguir añadiendo variables sólo "sumando" en la función

```{r}
modelo2<-lm(log_hrs ~ pb2 + as_label(pb1) + pa1, data=mydata, na.action=na.exclude)
summary(modelo2)
```


Y podemos ver si introducir esta variable afectó al ajuste global del modelo
```{r}
pruebaf1<-anova(modelo1, modelo2)
pruebaf1
```

Hoy que tenemos más variables podemos hablar de revisar dos supuestos más.

## Otros supuestos
Además de los supuestos de la regresión simple, podemos revisar estos otros. De nuevo, usaremos la librería "car",

1. Linealidad en los parámetros (será más díficil entre más variables tengamos)

2. La normalidad también, porque debe ser multivariada

3. Multicolinealidad
La prueba más común es la de Factor Influyente de la Varianza (VIF) por sus siglas en inglés. La lógica es que la multicolinealidad tendrá efectos en nuestro R2, inflándolo. De ahí que observamos de qué variable(s) proviene este problema relacionado con la multicolinealidad.

Si el valor es mayor a 5, tenemos un problema muy grave.

```{r}
vif(modelo2)
```


## Tabla de modelos estimados
Para los muy avanzados, con el paquete "stargazer" se pueden pasar a LaTeX fácilmente.

```{r mylatextable}
#stargazer(modelo0, modelo1,modelo2, type = 'latex', header=FALSE)

```

```{r mytextable}
stargazer(modelo, modelo1,modelo2, type = 'text', header=FALSE)

```

También la librería "sjPlot" tiene el comando "plot_model()"
(instala el comando si no lo tienes)

```{r}
library(sjPlot)
plot_model(modelo1)
plot_models(modelo, modelo1, modelo2)

```

# Ejercicio

Corra un modelo estadístico lineal con sus datos(seremos flexibles con la idea de "linealidad" y el tipo de relación) y verifique los supuestos. Agregue un recurso visual(un gráfico o una tabla)

Adjunte sus respuestas acá:

<https://forms.gle/uHEmpeBPnB1uMcW79>


