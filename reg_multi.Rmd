---
title: "Regresión lineal múltiple"
author: "AE"
date: "10/06/2022"
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
#  github_document:
#     toc: true
#     toc_depth: 2
# always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Paquetes necesarios en la práctica

Vamos a utilizad "pacman" para cargar los paquetes que utilizaremos en esta sesión

```{r, warning=FALSE}
#install.packages("sjPlot", dependencies=T) # solito porque da problmas
library(sjPlot)

if (!require("pacman")) install.packages("pacman") # instala pacman si se requiere
pacman::p_load(tidyverse, # sobretodo para dplyr
              haven, #importación
              janitor, #tablas
              sjlabelled, # etiquetas
              DescTools, # Paquete para estimaciones y pruebas
              infer, # tidy way 
              broom,  # Una escobita para limpiar (pero es para arreglar)
              estimatr, car, stargazer, ggpubr, 
              jtools, lm.beta, robustbase, sandwich,
              officer,flextable,huxtable, ggstance, kableExtra) # Para la regresión


```


#  Datos

Vamos a importar la base para Aguascalientes de la Encuesta Nacional de Ocupación y Empleo, trimestre I de 2021. 


>La Encuesta Nacional de Ocupación y Empleo (ENOE) es hoy día la encuesta continua levantada en hogares más grande que se aplica en el país. Su puesta en marcha en enero del 2005 marcó el fin de un modelo de captación y procesamiento que tuvo vigencia durante 20 años, el cual correspondió a la Encuesta Nacional de Empleo Urbano (ENEU) seguida por la Encuesta Nacional de Empleo (ENE) en donde aquélla quedó integrada. (INEGI, 2007)

Más acá:
<https://www.inegi.org.mx/programas/enoe/15ymas/>

```{r}
SDEMT122 <- read_dta("datos/SDEMT122.dta") 

```

[Esta base sólo contiene el estado de Aguascalientes para que sea menos pesada]



# Sub-setting para comparar modelos
Vamos a hacer una sub-base de nuestras posibles variables explicativas. Esto es importante porque sólo podemos comparar modelos con la misma cantidad de observaciones.


```{r}
mydata<- SDEMT122 %>% 
  filter(clase2==1) %>%  # me quedo con la población ocupada
  filter(ing_x_hrs>0) %>% # ingresos válidso
  filter(anios_esc<99) %>% # quito missings anios de escolaridad
  filter(eda>14 & eda<99) %>% #PET
  select(eda, sex, anios_esc, ing_x_hrs, pos_ocu, imssissste, medica5c, ent)  
  
tail(mydata)

```


```{r}
mydata %>% 
  ggplot()+ 
  aes(anios_esc, log(ing_x_hrs)) +
        geom_jitter()

mydata$log_ing_x_hrs<-log(mydata$ing_x_hrs)

cor(mydata$log_ing_x_hrs, mydata$anios_esc,  use = "pairwise")

```

Una prueba de hipotésis sobe la correlación

```{r}

cor_test<-mydata %>% 
  with(
    cor.test(log_ing_x_hrs, anios_esc, use="pairwise.complete.obs")
  )

#dos modos de visualizar el resultado
cor_test 
tidy(cor_test)

```


# Regresión lineal 

## Repaso Regresión lineal simple


$$y=\beta_o+\beta_1x +\epsilon$$

Donde los parámetros $\beta_o$ y $\beta_1$ describen la pendiente y el intercepto de la población, respectivamente.


La regresión lineal nos ayuda a describir una relación a través de una línea recta.

```{r}
hist(log(mydata$ing_x_hrs))
```

Una vez transformada nuestra variable, corremos el modelo

```{r}

modelo <-lm(log_ing_x_hrs ~anios_esc, data=mydata, 
            na.action=na.exclude)

summary(modelo) # resultados
```

Con "tidy()"

```{r}
tidy(modelo) # Pruebas de hipótesis de los coeficientes
```

Para obtener los intervalos de confianza, podemos hacerlo a partir del siguiente comando:

```{r}
confint(modelo)
```


Para el ajuste global del modelo, podemos utilzar el comando "glance()" sobre el objeto de nuestro modelo, ello nos dará la información correspondiente:
```{r}
glance(modelo) # resultado ajuste global

```
Otra manera de ver este ajuste es con el comando "anova()":
```{r}
anova(modelo)
```

## Repaso de Diagnósticos

```{r}
plot(modelo)

```




##1. Outliers y Normalidad
```{r}
# Assessing Outliers
outlierTest(modelo) # Bonferonni p-value for most extreme obs

out<-outlierTest(modelo) # guardamos en objeto
```


```{r}
qqPlot<-qqPlot(modelo)
ggpubr::ggqqplot(mydata$log_ing_x_hrs)
```


```{r}
car::qqPlot(modelo, main="QQ Plot") #qq plot for studentized resid
```
##2. Homocedasticidad

```{r}
# non-constant error variance test
ncvTest(modelo)
# plot studentized residuals vs. fitted values 
spreadLevelPlot(modelo)
```


¿Qué hacemos con los outliers?

Volvemos a correr nuestro modelo, hoy con una base que nos quite estas observaciones.

Como es nuestro modelo original, le pondremos cero

```{r}
names(out$bonf.p)

outliers<-rbind(as.integer(names(out$bonf.p)), qqPlot) # lista los casos 
```

Vamos a eliminar estos casos que son extremos (¡Ojo! esto tiene implicaciones de interpretación y debe ser justificado metodológicamente y ser señalado como una limitante)

Tenemos el nombre de las filas que nos dan problemas
```{r}
mydata$rownames<-rownames(mydata)
#View(mydata) # verificamos que no hayamos movido el orden

mydata2<-mydata[-outliers,]

```

Corremos un nuevo modelo

```{r}

modelo0<-lm(log_ing_x_hrs ~anios_esc, data=mydata2, na.action=na.exclude)
summary(modelo0)

```


¿Cuando parar?
```{r}
qqPlot(modelo0)
outlierTest(modelo0)

```

¡Este puede ser un proceso infinito! Si quitamos lo anormal, esto mueve nuestros rangos y al quitar un outlier, otra variable que antes no era outlier en el ajuste se puede convertir en outlier.



# Regresión Lineal múltiple

## Agregando una variable categórica

Sexo divide a nuestra población en dos grupos
```{r}
mydata %>% 
  ggplot()+ 
  aes(anios_esc,
      log(ing_x_hrs),
      color=as_label(sex)) +
  geom_jitter() +
  geom_smooth(method="lm")+
  facet_wrap(vars(as_label(sex)))
```


Cuando nosotros tenemos una variable categórica para la condición de sexo. 


$$y=\beta_o+\beta_1x + \delta_2x+ \epsilon$$


```{r}
modelo1<-lm(log_ing_x_hrs ~anios_esc + as_label(sex), data=mydata, na.action=na.exclude)
summary(modelo1)
```


Este modelo tiene coeficientes que deben leerse "condicionados". Es decir, en este caso tenemos que el coeficiente asociado a la edad, mantiene constante el valor de sexo y viceversa. 

¿Cómo saber is ha mejorado nuestro modelo? Podemos comparar el ajuste con la anova, es decir, una prueba F

```{r}
pruebaf0<-anova(modelo, modelo1)
pruebaf0
```


Como puedes ver, el resultado muestra "DF" (grados de libertad en español) de 1 (lo que indica que el modelo más complejo tiene un parámetro adicional) y un valor p muy pequeño (<.001). Esto significa que agregar el sexo al modelo lleva a un ajuste significativamente mejor sobre el modelo original.

Podemos seguir añadiendo variables sólo "sumando" en la función


$$y=\beta_o+\beta_1x + \delta_2x + \beta_3x + \epsilon$$



```{r}
modelo2<-lm(log_ing_x_hrs ~ anios_esc + as_label(sex) + eda, 
            data=mydata, 
            na.action=na.exclude)
summary(modelo2)
```


Y podemos ver si introducir esta variable afectó al ajuste global del modelo
```{r}
pruebaf1<-anova(modelo1, modelo2)
pruebaf1
```

Hoy que tenemos más variables podemos hablar de revisar dos supuestos más.

## Otros supuestos

Además de los supuestos de la regresión simple, podemos revisar estos otros. De nuevo, usaremos el paquete {car}

1. Linealidad en los parámetros (será más díficil entre más variables tengamos)

2. La normalidad también, porque debe ser multivariada

3. Multicolinealidad
La prueba más común es la de Factor Influyente de la Varianza (VIF) por sus siglas en inglés. La lógica es que la multicolinealidad tendrá efectos en nuestro R2, inflándolo. De ahí que observamos de qué variable(s) proviene este problema relacionado con la multicolinealidad.

Si el valor es mayor a 5, tenemos un problema muy grave.

```{r}
vif(modelo2)
```


## Tabla de modelos estimados
Para los muy avanzados, con el paquete "stargazer" se pueden pasar a LaTeX fácilmente.

```{r mylatextable}
#stargazer(modelo0, modelo1,modelo2, type = 'latex', header=FALSE)

```

```{r mytextable}
stargazer(modelo, modelo1,modelo2, type = 'text', header=FALSE)

```

También la librería "sjPlot" tiene el comando "plot_model()"
(instala el comando si no lo tienes)

```{r}
library(sjPlot)
plot_model(modelo1)
plot_models(modelo, modelo1, modelo2)

```

```{r}
tidy(modelo2)%>%
  kbl() %>%
  kable_paper("hover", full_width = F)
```


# Estandarizando que es gerundio

Comparar los resultados de los coeficientes es díficil, porque el efecto está medido en las unidades que fueron medidas. Por lo que no sería tan comparable el efecto que tenemos de nuestro índice sumativo (proporción de lugares con inseguridad declarada) con respecto a la eda (que se mide en años). Por lo que a veces es mejor usar las medida estandarizadas (es decir, nuestra puntajes z).

Podemos hacerlo transormando nuestras variables de origen e introducirlas al modelo. O bien, podemos usar un paquete que lo hace directamente. Los coeficientes calculados se les conoce como "beta"

Simplemente aplicamos el comando a nuestros modelos ya calculados

```{r}
lm.beta(modelo2)
```

Hoy la comparación será mucho más clara y podemos ver qué variable tiene mayor efecto en nuestra dependiente.

```{r}
modelo_beta<-lm.beta(modelo2)
modelo_beta
```

Para graficarlos, podemos usar de nuevo el comando plot_model(), con una opción

```{r}
plot_model(modelo2, type="std")
```

¿Qué podemos concluir de estos resultados?


# Post-estimación

## Las predicciones

Para ello a veces es mejor transformar nuestras variables estiquetadas. Reescribimos nuestro modelo

```{r}
mydata<-mydata %>% 
  mutate(sex=as_label(sex))

modelo2<-lm(log_ing_x_hrs ~ anios_esc +sex + eda, data=mydata)

summary(modelo2)
```

Unos de los usos más comunes de los modelos estadísticos es la predicción

```{r}
sjPlot::plot_model(modelo2, type="pred", terms = "anios_esc")
```

También podemos incluir la predecciones para los distintos valores de las variables
```{r}
plot_model(modelo2, type="pred", terms = c("anios_esc","sex")) + theme_blank()
```

El orden de los términos importa:
```{r}
plot_model(modelo2, type="pred", terms = c("sex","anios_esc")) + theme_blank()
```

## Efectos marginales
Con los efectos marginales, por otro lado medimos el efecto promedio, dejando el resto de variables constantes.

```{r}
plot_model(modelo2, type="eff", terms = "anios_esc")
plot_model(modelo2, type="eff", terms = "sex")

```
¿Es el mismo gráfico que con "pred"? Veamos la ayuda

¿Y si queremos ver esta informaicón graficada?
```{r}
eff<-plot_model(modelo2, type="eff", terms = "anios_esc")
eff$data

```


```{r}
eff<-plot_model(modelo2, type="pred", terms = "anios_esc")
eff$data
```

# Extensiones del modelo de regresión

## Introducción a las interacciones

Muchas veces las variables explicativas van a tener relación entre sí. Por ejemplo ¿Las horas tendrá que ver con el sexo y afectan no sólo en intercepto si no también la pendiente? Para ello podemos introducir una interacción

```{r}
modelo_int1<-lm(log_ing_x_hrs ~ anios_esc * sex , data = mydata, na.action=na.exclude)
summary(modelo_int1)
```

Esta interacción lo que asume es que las pendientes pueden moverse (aunque en este caso específico no lo hacen tanto porque no nos salió significativa)

```{r}
plot_model(modelo_int1, type="int", terms = c("sex", "anios_esc"))

```

## Efectos no lineales

### Explicitando el logaritmo


```{r}
mydata2<-mydata %>% filter(anios_esc>0)
modelo_log<-lm(log(ing_x_hrs) ~ log(anios_esc) + sex,
               data=mydata2, 
               na.action = na.exclude)

summary(modelo_log)

```


```{r}
plot_model(modelo_log, type="pred", terms ="anios_esc")

```

### Efecto cuadrático (ojo con la sintaxis)

```{r}
modelo_quadr<-lm(log_ing_x_hrs ~ anios_esc + I(anios_esc^2) + sex, 
                 data=mydata, 
                 na.action=na.exclude)
summary(modelo_quadr)

```

Quizás con un gráfico de lo predicho tenemos más claro lo que hace ese término

```{r}
plot_model(modelo_quadr, type="pred", terms = c("anios_esc"))

```

En efecto, lo que nos da el signo del cuadrático puede hablarnos del comportamiento  cóncavo hacia arriba o hacia abajo. La edad muchas veces tiene este comportamiento en algunos fenómenos.



# No cumplo los supuestos

## Heterocedasticidad
El problema de la heterocedasticidad es que los errores estándar de subestiman, por lo que si estos están en el cociente de nuestro estadístico de prueba t, esto implicaría que nuestras pruebas podrían estar arrojando valores significativos cuando no lo son. 

Una forma muy sencilla es pedir los errores robustos, esto se puede desarrollar con el paquete "estimatr" <https://declaredesign.org/r/estimatr/articles/getting-started.html>


```{r}
modelo2rob1 <- lm_robust(log_ing_x_hrs ~ anios_esc + as_label(sex) + eda, data = mydata)
summary(modelo2rob1)
tidy(modelo2rob1)
```

## Errores en clúster

Cuando tenemos individuos que pertenecen a una misma unidad, podemos crear errores anidados en clúster:

```{r}
# cluster robust standard errors
modelo2rob2<- lm_robust(log_ing_x_hrs ~ anios_esc + as_label(sex) + eda, data = mydata, clusters = ent)
# standard summary view also available
summary(modelo2rob2)
```

## Jtools
Jacob Long is back!

<https://cran.r-project.org/web/packages/jtools/vignettes/summ.html>

```{r}
summ(modelo2, robust = "HC1")
```

También "summ" funciona para estandarizar:
```{r}
summ(modelo2, scale = TRUE)

```


# Regresión robusta

```{r}
library(robustbase)
modelo2rob3<-lmrob(log_ing_x_hrs ~ anios_esc + as_label(sex) + eda, data = mydata, 
    na.action = na.exclude)
summary(modelo2rob3)

```
No es lo mismo la regresión robusta que los errores robustos. La regresión robusta es más robusta a los outliers. No confundir.

La regresión robusta, es esto, robusta a los outliers, porque pesa el valor de las observaciones de tal manera que los outliers tenga menor influencia.

# Comparando modelos

Usaremos "stargazer" para revisar nuestros modelos. Los modelos que usamos con "estimatr" al tener más información (como los intervalos de confianza), no podemos introducirlos directamente.
```{r mytextable2}
stargazer(modelo2, modelo2rob3, type = 'text', header=FALSE)

```

Así que ni modo. Stargazer nos acompañó mucho mucho tiempo. Pero parece ser que quién lo creó no lo quiere cambiar ¿qué hacer? Pues Jacob Long nos salvó la vida:

```{r}
jtools:::export_summs(modelo2, modelo2rob1, modelo2rob2, modelo2rob3)

```

Estas tablas también están muy lindas y pueden exportarse a otros formatos:
```{r}
#jtools::export_summs(modelo2, modelo2rob1, modelo2rob2, modelo2rob3, to.file = "PDF", file.name = "test.pdf")
```


# Extra:

Revisando jtools:

```{r}
plot_summs(modelo2,
          scale=T,
          plot.distributions = TRUE, 
          inner_ci_level = .9)
```

# Un poquito de reflexión

Se pueden usar métodos no paramétricos, como la regresión mediana (checar el paquete "quantreg". O como ya vimos podemos transformar la variable a logaritmo, seleccionar casos. 

Es recomendable mejor utilizar otro tipo de modelos más robustos a la presencia de outliers (i.e. regresión robusta) y menos dependientes de una distribución normal (i.e. regresión mediana).
